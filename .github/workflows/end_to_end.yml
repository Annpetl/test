name: E2E Tests

on:
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      env:
        description: "Target environment"
        required: false
        default: "staging"
        type: choice
        options:
          - staging
      tenant:
        description: "Tenant name"
        required: false
        type: choice
        options:
          - videoland
      customer:
        description: "Customer name"
        required: false
        type: choice
        options:
          - rtlnl
  workflow_call:
    inputs:
      env:
        required: true
        type: string
      tenant:
        required: true
        type: string
      customer:
        required: true
        type: string
      pr_number:
        required: true
        type: string

permissions:
  pull-requests: write
  contents: read

jobs:
  e2e-tests:
    name: Run E2E Tests
    runs-on: ubuntu-latest
    environment: ${{ inputs.env || 'staging' }}

    steps:
      - name: Set BASE_URL based on environment
        env:
          PR_NUMBER: ${{ inputs.pr_number || github.event.pull_request.number || 1 }}
        run: |
          if [ -n "$PR_NUMBER" ] && [ "$PR_NUMBER" != "1" ]; then
            BASE_URL="https://content-discovery-assistant-${{ inputs.customer }}-$PR_NUMBER.preview.${{ inputs.tenant }}.bedrock.tech"
          else
            BASE_URL="https://content-discovery-assistant-${{ inputs.customer }}.staging.${{ inputs.tenant }}.bedrock.tech"
          fi
          echo "BASE_URL=$BASE_URL" >> $GITHUB_ENV
          echo "Using BASE_URL: $BASE_URL"

      - name: Checkout
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install pipx
          pipx install poetry==1.8.2
          poetry install 

      - name: Run tests with JUnit output
        run: |
          set +e
          poetry run pytest -c tests/e2e_tests.ini \
            --junitxml=test-results/junit.xml \
            --html=test-results/report.html \
            --self-contained-html
          pytest_exit=$?
          set -e

          # Create basic summary file
          echo "### Test Environment" > summary.md
          echo "- Base URL: $BASE_URL" >> summary.md
          echo "- Environment: ${{ inputs.env || 'staging' }}" >> summary.md
          echo "" >> summary.md

          # Exit with proper code
          if [ $pytest_exit -ne 0 ]; then
            echo "## ❌ Some tests failed" >> summary.md
            exit $pytest_exit
          else
            echo "## ✅ All tests passed" >> summary.md
          fi

      - name: Upload HTML report
        uses: actions/upload-artifact@v4
        with:
          name: html-test-report
          path: test-results/report.html

      - name: Publish Test Results
        uses: dorny/test-reporter@v2
        if: always()
        with:
          name: 'E2E Test Results'
          path: 'test-results/junit.xml'
          reporter: 'java-junit'
          fail-on-error: true
          only-summary: false
          show-test-log: true
          show-error-details: true
          max-annotations: 50

      - name: Post environment summary
        uses: marocchino/sticky-pull-request-comment@v2
        if: ${{ github.event_name == 'pull_request' }}
        with:
          path: summary.md
          header: test-environment
          recreate: true

      - name: Add to workflow summary
        run: |
          echo "### 🧪 E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** ${{ inputs.env || 'staging' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Base URL:** ${{ env.BASE_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat summary.md >> $GITHUB_STEP_SUMMARY